{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING HOMEWORK\n",
    "\n",
    "You may discuss and work with whomever you like, but each person should submit their own code and you must list your collaborators.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and manipulating images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xarr = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]\n",
      "\n",
      "xarr[::3] = [ 0  3  6  9 12 15 18 21 24 27 30 33 36 39 42 45 48]\n",
      "\n",
      "xarr[::-1] = [49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25\n",
      " 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10  9  8  7  6  5  4  3  2  1  0]\n",
      "\n",
      "xarr[4:31:5] = [ 4  9 14 19 24 29]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xarr = np.arange(50)\n",
    "print(\"xarr = {0}\\n\".format(xarr))\n",
    "print(\"xarr[::3] = {0}\\n\".format(xarr[::3]))\n",
    "print(\"xarr[::-1] = {0}\\n\".format(xarr[::-1]))\n",
    "print(\"xarr[4:31:5] = {0}\\n\".format(xarr[4:31:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task for this problem is to write a python code called image_manipulation.py that can be executed by typing \n",
    "\n",
    "    python image_manipulation.py\n",
    "    \n",
    "in the main atui_uc17 directory.\n",
    "\n",
    "This code should first import,\n",
    "\n",
    "    import os\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import scipy.ndimage as nd\n",
    "    from scipy.ndimage.filters import median_filter as mf\n",
    "\n",
    "and then:\n",
    "\n",
    "1. Perform the following operations in **one line of code** (points will be deducted for each extra line of code used, and using semicolons does not count)\n",
    "\n",
    "    - read in the file city_image.jpg\n",
    "    - select every other pixel\n",
    "    - invert the color values so that red is blue and blue is red\n",
    "    - convert to a negative of the image\n",
    "    - convert to floating point and smooth by a median filter of width 8 in row, 2 in column, and 1 in color\n",
    "    - clip to [0,255]\n",
    "    - convert back to numpy unsigned 8-bit integers\n",
    "\n",
    "Display the result of 1. in a matplotlib window in which the image completely fills the window, the axis is turned off, and *the figure window title* (**not the axis title!**) is set to \"modified city image\" (nb, we haven't done that last one in class, but as a hint, there is a method for it in a matplotlib figure.canvas object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as nd\n",
    "from scipy.ndimage.filters import median_filter as mf\n",
    "%matplotlib tk\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_img = nd.imread('images/city_image.jpg') # read in city_img.jpb\n",
    "city_img[::2] = (np.flip(city_img[::2],2)) # select every other pixel and switch red and blue values\n",
    "city_neg = 255 - city_img # convert to negative (entire image, not just every other pixel)\n",
    "filtered = mf(city_neg.astype('float'),size=(8,2,1)) # convert to floating point and smooth with size (8,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255.0, 15.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.max(), filtered.min() #... but the color values are already between 15 and 255... why do we need to clip? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(num=1)\n",
    "ax1.axis(\"off\")\n",
    "im1 = ax1.imshow(filtered.clip(0, 255).astype(np.uint8)) # clip to (0 - 255) and convert back to integer?\n",
    "ax1.grid(0)\n",
    "fig1.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Image directory preview and exploration widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will create a widget to quickly explore the image contents of a directory.  Write a python code called image_preview.py to be exceuted in the atui_uc17/images directory as \n",
    "\n",
    "    python image_preview.py\n",
    "\n",
    "The code should do the following:\n",
    "\n",
    "1. get the file list of all .jpg files in the current directory.\n",
    "\n",
    "2. Display the first image in a matplotlib window in which the image completely fills the window, the axis is turned off, and the figure window title is the file name.\n",
    "\n",
    "3. Bind the left and right arrow keys of the keyboard to a function which replaces the displayed data with either the next (right arrow key) or previous (left arrow key) image in the list and updates the window title.\n",
    "\n",
    "4. Bind the up and down arrow keys to do the same thing as 3., but instead of next and previous, have the new image be 10 ahead or 10 behind the current image.\n",
    "\n",
    "** for 3. and 4. make sure that pressing the left arrow when the first image on the list is displayed wraps around to the end of the file list and if the last image is displayed, the right arrow wraps around to the beginning.  **\n",
    "\n",
    "5. Bind the \"n\" key to toggle between the negative of the image.\n",
    "\n",
    "6. Bind the \"e\" key to a function that *opens a new matplotlib window* that shows the absolute value of the gaussian derivative of the image with a smoothing $\\sigma$ of 2 and a derivative stepsize of 1.  ** Do not display the gaussian derivative in the same window as the original image. **\n",
    "\n",
    "7. Bind the \"h\" key to a function that opens a new matplotlib window and displays (with three axes) the color histogram of the displayed image.  The histogram should have 256 bins and a range 0 to 255.\n",
    "\n",
    "8. Any open windows from step 5-7 should be closed when pressing any of the arrow keys to go to the next image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hand written digit recognition accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, I remarked that our hand written digit recognition method was not particularly good, but also had a hard time finding a case where it failed.  Let's find out how good it is.\n",
    "\n",
    "Write a code called regression_accuracy.py to be run in the atui_uc17 directory so that it can be executed as\n",
    "\n",
    "    python regression_accuracy.py\n",
    "    \n",
    "The code should perform the regression that we did in class (where an image of a digit was regressed against the mean images of the 10 digits and the \"choice\" is made by selecting the highest regression coefficent) for **all** the images in the data set.  The outputs should be\n",
    "\n",
    "1. A text output listing the percentage of failures and the most common guess for those failures.  I.e. something like:\n",
    "\n",
    "    25% of 1's were incorrectly identified, the most common guess for those failures was 7<br>\n",
    "    27% of 2's were incorrectly identified, the most common guess for those failures was 4<br>\n",
    "    etc.<br><br>\n",
    "\n",
    "2. A 10 second animation showing some of the failures and their guesses (with a 0.2 second delay between frames) <br><br>\n",
    "\n",
    "**Bonus points:**<br>\n",
    "I mentioned in class that these are regression coefficients and not correlation coefficients which should be between -1 and 1.  To find the correlation coefficients, each image and template must have its mean subtracted and then be normalized by its standard deviation.  Write a code called correlation_accuracy.py to be run in the atui_uc17 directory so that it can be executed as\n",
    "\n",
    "    python correlation_accuracy.py\n",
    "    \n",
    "which repeats steps 1 and 2 above but using correlation coefficients instead of regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Background subtraction in video using median filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we separated cars from background by taking the mean across time steps and subtracting that background estimate from each image.  There are several standard techniques to create a more robust background, one of which uses the median filter.  Write a python code called video_median_background.py to be executed in the main atui_uc17 directory as:\n",
    "\n",
    "    python video_median_background.py\n",
    "    \n",
    "That accomplishes the following tasks:\n",
    "\n",
    "1. Read in the images in the images/dot/ folder as we did in class, but converting to luminosity by taking the mean across color channels as each image is read in (this should resut in a 100x240x350 floating point array of images).\n",
    "\n",
    "2. Generate a \"temporally median filtered\" image set by applying a median filter across the *time axis only* (axis 0 in the example in class), not the spatial axes, with a width of 5.  Note, unlike the gaussian filter which has no effect when $\\sigma$ is set to 0, the median filter requires a width of at least 1, otherwise you will get an error that the filter footprint is the wrong size.  A width of 1 for the median filter implimentation in scipy.ndimage.filters.median_filter means the filter has no effect.\n",
    "\n",
    "3. Create a background by taking the temporal mean of these median filtered images in 2.\n",
    "\n",
    "4. Create a foreground image set by subtracting the result of 3. from the images in 1.\n",
    "\n",
    "5. Create a second foreground image set by doing what we did in class which was subtracting the temporal mean of the images in 1. from the images in 1.\n",
    "\n",
    "6. Show that the \"temporally median filtered\" background is a little bit better along the roadway by displaying the absolute value of the result at time step 20 (image index 20) of 4. and 5. side-by-side using \"gist_gray\" for a color map and setting clim=[0, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
